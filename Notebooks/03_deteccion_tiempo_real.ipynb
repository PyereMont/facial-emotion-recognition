{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a043f11a",
   "metadata": {},
   "source": [
    "# üé• Detector de Emociones Faciales - Detecci√≥n en Tiempo Real\n",
    "\n",
    "## Objetivo\n",
    "Crear una aplicaci√≥n que use la **webcam** para detectar rostros y clasificar emociones en tiempo real.\n",
    "\n",
    "## Funcionamiento\n",
    "1. **Capturar video** de la webcam\n",
    "2. **Detectar rostros** usando Haar Cascade de OpenCV\n",
    "3. **Preprocesar** el rostro (48x48, escala de grises, normalizar)\n",
    "4. **Predecir emoci√≥n** con nuestro modelo CNN\n",
    "5. **Mostrar resultado** en pantalla con la emoci√≥n y confianza\n",
    "\n",
    "## Controles\n",
    "- **Presiona 'q'** para salir\n",
    "- **Presiona 's'** para capturar screenshot\n",
    "- **ESC** tambi√©n cierra la aplicaci√≥n\n",
    "\n",
    "¬°Prep√°rate para hacer diferentes expresiones faciales! üòäüò¢üò†üòÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98db3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas\n",
      "OpenCV version: 4.8.1\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Configuraci√≥n\n",
    "print(\"‚úÖ Librer√≠as importadas\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667bbef",
   "metadata": {},
   "source": [
    "## ü§ñ Cargar Modelo Entrenado\n",
    "\n",
    "Cargaremos el mejor modelo (V2) que entrenamos con 60% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8096724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando modelo entrenado...\n",
      "‚úÖ Modelo cargado exitosamente\n",
      "\n",
      "üé≠ Emociones a detectar: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "üìä Modelo entrenado con 60% accuracy\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado\n",
    "model_path = Path('../models/best_model_v2.keras')\n",
    "\n",
    "print(\"üìÇ Cargando modelo entrenado...\")\n",
    "if model_path.exists():\n",
    "    model = keras.models.load_model(model_path)\n",
    "    print(\"‚úÖ Modelo cargado exitosamente\")\n",
    "else:\n",
    "    print(\"‚ùå Error: Modelo no encontrado\")\n",
    "    print(f\"   Busca en: {model_path.absolute()}\")\n",
    "\n",
    "# Definir emociones (mismo orden que en el entrenamiento)\n",
    "emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "# Emojis para cada emoci√≥n\n",
    "emotion_emojis = {\n",
    "    'angry': 'üò†',\n",
    "    'disgust': 'ü§¢',\n",
    "    'fear': 'üò®',\n",
    "    'happy': 'üòä',\n",
    "    'neutral': 'üòê',\n",
    "    'sad': 'üò¢',\n",
    "    'surprise': 'üòÆ'\n",
    "}\n",
    "\n",
    "print(f\"\\nüé≠ Emociones a detectar: {emotions}\")\n",
    "print(f\"üìä Modelo entrenado con 60% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f448cbf",
   "metadata": {},
   "source": [
    "## üë§ Detector de Rostros\n",
    "\n",
    "Usaremos **Haar Cascade** de OpenCV para detectar rostros en el video.\n",
    "Este es un detector cl√°sico, r√°pido y eficiente para detecci√≥n facial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a77e261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Detector de rostros cargado correctamente\n",
      "üìÅ Ruta: c:\\Users\\patri\\miniconda3\\envs\\detector-emociones\\lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "# Cargar clasificador Haar Cascade para detecci√≥n de rostros\n",
    "face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "\n",
    "if face_cascade.empty():\n",
    "    print(\"‚ùå Error: No se pudo cargar el detector de rostros\")\n",
    "else:\n",
    "    print(\"‚úÖ Detector de rostros cargado correctamente\")\n",
    "    print(f\"üìÅ Ruta: {face_cascade_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b0667",
   "metadata": {},
   "source": [
    "## üîß Funciones de Procesamiento\n",
    "\n",
    "Crearemos funciones para:\n",
    "1. Preprocesar el rostro detectado (resize, normalizar)\n",
    "2. Predecir la emoci√≥n\n",
    "3. Dibujar resultados en la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc49733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones de procesamiento creadas\n"
     ]
    }
   ],
   "source": [
    "def preprocess_face(face_img):\n",
    "    \"\"\"\n",
    "    Preprocesa la imagen del rostro para el modelo\n",
    "    \"\"\"\n",
    "    # Convertir a escala de grises si es necesario\n",
    "    if len(face_img.shape) == 3:\n",
    "        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Redimensionar a 48x48\n",
    "    face_img = cv2.resize(face_img, (48, 48))\n",
    "    \n",
    "    # Normalizar (0-1)\n",
    "    face_img = face_img / 255.0\n",
    "    \n",
    "    # Reshape para el modelo (batch, height, width, channels)\n",
    "    face_img = face_img.reshape(1, 48, 48, 1)\n",
    "    \n",
    "    return face_img\n",
    "\n",
    "\n",
    "def predict_emotion(face_img, model):\n",
    "    \"\"\"\n",
    "    Predice la emoci√≥n del rostro\n",
    "    \"\"\"\n",
    "    # Preprocesar\n",
    "    processed_face = preprocess_face(face_img)\n",
    "    \n",
    "    # Predecir\n",
    "    predictions = model.predict(processed_face, verbose=0)\n",
    "    \n",
    "    # Obtener emoci√≥n con mayor probabilidad\n",
    "    emotion_idx = np.argmax(predictions[0])\n",
    "    emotion = emotions[emotion_idx]\n",
    "    confidence = predictions[0][emotion_idx]\n",
    "    \n",
    "    return emotion, confidence, predictions[0]\n",
    "\n",
    "\n",
    "def draw_emotion_results(frame, x, y, w, h, emotion, confidence):\n",
    "    \"\"\"\n",
    "    Dibuja el rect√°ngulo y la emoci√≥n en el frame\n",
    "    \"\"\"\n",
    "    # Colores seg√∫n la emoci√≥n\n",
    "    colors = {\n",
    "        'angry': (0, 0, 255),      # Rojo\n",
    "        'disgust': (0, 128, 128),  # Verde oscuro\n",
    "        'fear': (128, 0, 128),     # P√∫rpura\n",
    "        'happy': (0, 255, 0),      # Verde\n",
    "        'neutral': (128, 128, 128),# Gris\n",
    "        'sad': (255, 0, 0),        # Azul\n",
    "        'surprise': (0, 255, 255)  # Amarillo\n",
    "    }\n",
    "    \n",
    "    color = colors.get(emotion, (255, 255, 255))\n",
    "    \n",
    "    # Dibujar rect√°ngulo alrededor del rostro\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "    \n",
    "    # Texto de la emoci√≥n con emoji\n",
    "    emoji = emotion_emojis.get(emotion, 'üòê')\n",
    "    text = f\"{emoji} {emotion.upper()} ({confidence*100:.1f}%)\"\n",
    "    \n",
    "    # Fondo para el texto\n",
    "    (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "    cv2.rectangle(frame, (x, y - text_h - 10), (x + text_w, y), color, -1)\n",
    "    \n",
    "    # Texto\n",
    "    cv2.putText(frame, text, (x, y - 5), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "print(\"‚úÖ Funciones de procesamiento creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab954d8",
   "metadata": {},
   "source": [
    "## üé• Detecci√≥n en Tiempo Real\n",
    "\n",
    "Esta funci√≥n activar√° tu webcam y detectar√° emociones en tiempo real.\n",
    "\n",
    "**Controles:**\n",
    "- Presiona **'q'** para salir\n",
    "- Presiona **'s'** para guardar screenshot\n",
    "- Presiona **ESC** tambi√©n cierra la aplicaci√≥n\n",
    "\n",
    "¬°Prep√°rate para hacer diferentes caras! üòäüò¢üò†üòÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bec665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n de detecci√≥n en tiempo real creada\n",
      "\n",
      "üöÄ Para iniciar la detecci√≥n, ejecuta la siguiente celda\n"
     ]
    }
   ],
   "source": [
    "def run_emotion_detection():\n",
    "    \"\"\"\n",
    "    Funci√≥n principal para detecci√≥n de emociones en tiempo real\n",
    "    \"\"\"\n",
    "    # Iniciar captura de video\n",
    "    print(\"üé• Iniciando webcam...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Error: No se pudo acceder a la webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"‚úÖ Webcam iniciada\")\n",
    "    print(\"\\nüìã CONTROLES:\")\n",
    "    print(\"  - Presiona 'q' para salir\")\n",
    "    print(\"  - Presiona 's' para guardar screenshot\")\n",
    "    print(\"  - Presiona ESC para salir\")\n",
    "    print(\"\\nüé≠ ¬°Haz diferentes expresiones faciales!\")\n",
    "    \n",
    "    screenshot_count = 0\n",
    "    \n",
    "    while True:\n",
    "        # Capturar frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"‚ùå Error al capturar frame\")\n",
    "            break\n",
    "        \n",
    "        # Convertir a escala de grises para detecci√≥n\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detectar rostros\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(48, 48)\n",
    "        )\n",
    "        \n",
    "        # Procesar cada rostro detectado\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extraer regi√≥n del rostro\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            # Predecir emoci√≥n\n",
    "            emotion, confidence, all_predictions = predict_emotion(face_roi, model)\n",
    "            \n",
    "            # Dibujar resultados\n",
    "            frame = draw_emotion_results(frame, x, y, w, h, emotion, confidence)\n",
    "        \n",
    "        # Mostrar informaci√≥n en pantalla\n",
    "        cv2.putText(frame, f\"Rostros detectados: {len(faces)}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, \"Presiona 'q' para salir | 's' para screenshot\", (10, frame.shape[0] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Mostrar frame\n",
    "        cv2.imshow('Detector de Emociones Faciales', frame)\n",
    "        \n",
    "        # Controles de teclado\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == 27:  # 'q' o ESC\n",
    "            print(\"\\nüëã Cerrando aplicaci√≥n...\")\n",
    "            break\n",
    "        elif key == ord('s'):  # Guardar screenshot\n",
    "            screenshot_count += 1\n",
    "            filename = f'../data/screenshot_{screenshot_count}.jpg'\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"üì∏ Screenshot guardado: {filename}\")\n",
    "    \n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"‚úÖ Aplicaci√≥n cerrada correctamente\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de detecci√≥n en tiempo real creada\")\n",
    "print(\"\\nüöÄ Para iniciar la detecci√≥n, ejecuta la siguiente celda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caba088",
   "metadata": {},
   "source": [
    "## üöÄ ¬°Iniciar Detecci√≥n!\n",
    "\n",
    "Ejecuta la siguiente celda para activar tu webcam y empezar a detectar emociones.\n",
    "\n",
    "**Tips:**\n",
    "- Aseg√∫rate de tener buena iluminaci√≥n\n",
    "- Mira directamente a la c√°mara\n",
    "- Prueba diferentes expresiones: sonr√≠e, en√≥jate, sorpr√©ndete\n",
    "- El modelo funciona mejor con expresiones claras y exageradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd184f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üé• DETECTOR DE EMOCIONES FACIALES EN TIEMPO REAL\n",
      "============================================================\n",
      "üé• Iniciando webcam...\n",
      "‚úÖ Webcam iniciada\n",
      "\n",
      "üìã CONTROLES:\n",
      "  - Presiona 'q' para salir\n",
      "  - Presiona 's' para guardar screenshot\n",
      "  - Presiona ESC para salir\n",
      "\n",
      "üé≠ ¬°Haz diferentes expresiones faciales!\n"
     ]
    }
   ],
   "source": [
    "# ¬°INICIAR DETECCI√ìN DE EMOCIONES!\n",
    "print(\"=\" * 60)\n",
    "print(\"üé• DETECTOR DE EMOCIONES FACIALES EN TIEMPO REAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "run_emotion_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detector-emociones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

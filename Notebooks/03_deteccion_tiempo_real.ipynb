{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a043f11a",
   "metadata": {},
   "source": [
    "# 🎥 Detector de Emociones Faciales - Detección en Tiempo Real\n",
    "\n",
    "## Objetivo\n",
    "Crear una aplicación que use la **webcam** para detectar rostros y clasificar emociones en tiempo real.\n",
    "\n",
    "## Funcionamiento\n",
    "1. **Capturar video** de la webcam\n",
    "2. **Detectar rostros** usando Haar Cascade de OpenCV\n",
    "3. **Preprocesar** el rostro (48x48, escala de grises, normalizar)\n",
    "4. **Predecir emoción** con nuestro modelo CNN\n",
    "5. **Mostrar resultado** en pantalla con la emoción y confianza\n",
    "\n",
    "## Controles\n",
    "- **Presiona 'q'** para salir\n",
    "- **Presiona 's'** para capturar screenshot\n",
    "- **ESC** también cierra la aplicación\n",
    "\n",
    "¡Prepárate para hacer diferentes expresiones faciales! 😊😢😠😮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98db3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Librerías importadas\n",
      "OpenCV version: 4.8.1\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Configuración\n",
    "print(\"✅ Librerías importadas\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667bbef",
   "metadata": {},
   "source": [
    "## 🤖 Cargar Modelo Entrenado\n",
    "\n",
    "Cargaremos el mejor modelo (V2) que entrenamos con 60% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8096724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Cargando modelo entrenado...\n",
      "✅ Modelo cargado exitosamente\n",
      "\n",
      "🎭 Emociones a detectar: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "📊 Modelo entrenado con 60% accuracy\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado\n",
    "model_path = Path('../models/best_model_v2.keras')\n",
    "\n",
    "print(\"📂 Cargando modelo entrenado...\")\n",
    "if model_path.exists():\n",
    "    model = keras.models.load_model(model_path)\n",
    "    print(\"✅ Modelo cargado exitosamente\")\n",
    "else:\n",
    "    print(\"❌ Error: Modelo no encontrado\")\n",
    "    print(f\"   Busca en: {model_path.absolute()}\")\n",
    "\n",
    "# Definir emociones (mismo orden que en el entrenamiento)\n",
    "emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "# Emojis para cada emoción\n",
    "emotion_emojis = {\n",
    "    'angry': '😠',\n",
    "    'disgust': '🤢',\n",
    "    'fear': '😨',\n",
    "    'happy': '😊',\n",
    "    'neutral': '😐',\n",
    "    'sad': '😢',\n",
    "    'surprise': '😮'\n",
    "}\n",
    "\n",
    "print(f\"\\n🎭 Emociones a detectar: {emotions}\")\n",
    "print(f\"📊 Modelo entrenado con 60% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f448cbf",
   "metadata": {},
   "source": [
    "## 👤 Detector de Rostros\n",
    "\n",
    "Usaremos **Haar Cascade** de OpenCV para detectar rostros en el video.\n",
    "Este es un detector clásico, rápido y eficiente para detección facial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a77e261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Detector de rostros cargado correctamente\n",
      "📁 Ruta: c:\\Users\\patri\\miniconda3\\envs\\detector-emociones\\lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "# Cargar clasificador Haar Cascade para detección de rostros\n",
    "face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "\n",
    "if face_cascade.empty():\n",
    "    print(\"❌ Error: No se pudo cargar el detector de rostros\")\n",
    "else:\n",
    "    print(\"✅ Detector de rostros cargado correctamente\")\n",
    "    print(f\"📁 Ruta: {face_cascade_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b0667",
   "metadata": {},
   "source": [
    "## 🔧 Funciones de Procesamiento\n",
    "\n",
    "Crearemos funciones para:\n",
    "1. Preprocesar el rostro detectado (resize, normalizar)\n",
    "2. Predecir la emoción\n",
    "3. Dibujar resultados en la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc49733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones de procesamiento creadas\n"
     ]
    }
   ],
   "source": [
    "def preprocess_face(face_img):\n",
    "    \"\"\"\n",
    "    Preprocesa la imagen del rostro para el modelo\n",
    "    \"\"\"\n",
    "    # Convertir a escala de grises si es necesario\n",
    "    if len(face_img.shape) == 3:\n",
    "        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Redimensionar a 48x48\n",
    "    face_img = cv2.resize(face_img, (48, 48))\n",
    "    \n",
    "    # Normalizar (0-1)\n",
    "    face_img = face_img / 255.0\n",
    "    \n",
    "    # Reshape para el modelo (batch, height, width, channels)\n",
    "    face_img = face_img.reshape(1, 48, 48, 1)\n",
    "    \n",
    "    return face_img\n",
    "\n",
    "\n",
    "def predict_emotion(face_img, model):\n",
    "    \"\"\"\n",
    "    Predice la emoción del rostro\n",
    "    \"\"\"\n",
    "    # Preprocesar\n",
    "    processed_face = preprocess_face(face_img)\n",
    "    \n",
    "    # Predecir\n",
    "    predictions = model.predict(processed_face, verbose=0)\n",
    "    \n",
    "    # Obtener emoción con mayor probabilidad\n",
    "    emotion_idx = np.argmax(predictions[0])\n",
    "    emotion = emotions[emotion_idx]\n",
    "    confidence = predictions[0][emotion_idx]\n",
    "    \n",
    "    return emotion, confidence, predictions[0]\n",
    "\n",
    "\n",
    "def draw_emotion_results(frame, x, y, w, h, emotion, confidence):\n",
    "    \"\"\"\n",
    "    Dibuja el rectángulo y la emoción en el frame\n",
    "    \"\"\"\n",
    "    # Colores según la emoción\n",
    "    colors = {\n",
    "        'angry': (0, 0, 255),      # Rojo\n",
    "        'disgust': (0, 128, 128),  # Verde oscuro\n",
    "        'fear': (128, 0, 128),     # Púrpura\n",
    "        'happy': (0, 255, 0),      # Verde\n",
    "        'neutral': (128, 128, 128),# Gris\n",
    "        'sad': (255, 0, 0),        # Azul\n",
    "        'surprise': (0, 255, 255)  # Amarillo\n",
    "    }\n",
    "    \n",
    "    color = colors.get(emotion, (255, 255, 255))\n",
    "    \n",
    "    # Dibujar rectángulo alrededor del rostro\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "    \n",
    "    # Texto de la emoción con emoji\n",
    "    emoji = emotion_emojis.get(emotion, '😐')\n",
    "    text = f\"{emoji} {emotion.upper()} ({confidence*100:.1f}%)\"\n",
    "    \n",
    "    # Fondo para el texto\n",
    "    (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "    cv2.rectangle(frame, (x, y - text_h - 10), (x + text_w, y), color, -1)\n",
    "    \n",
    "    # Texto\n",
    "    cv2.putText(frame, text, (x, y - 5), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "print(\"✅ Funciones de procesamiento creadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab954d8",
   "metadata": {},
   "source": [
    "## 🎥 Detección en Tiempo Real\n",
    "\n",
    "Esta función activará tu webcam y detectará emociones en tiempo real.\n",
    "\n",
    "**Controles:**\n",
    "- Presiona **'q'** para salir\n",
    "- Presiona **'s'** para guardar screenshot\n",
    "- Presiona **ESC** también cierra la aplicación\n",
    "\n",
    "¡Prepárate para hacer diferentes caras! 😊😢😠😮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bec665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Función de detección en tiempo real creada\n",
      "\n",
      "🚀 Para iniciar la detección, ejecuta la siguiente celda\n"
     ]
    }
   ],
   "source": [
    "def run_emotion_detection():\n",
    "    \"\"\"\n",
    "    Función principal para detección de emociones en tiempo real\n",
    "    \"\"\"\n",
    "    # Iniciar captura de video\n",
    "    print(\"🎥 Iniciando webcam...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Error: No se pudo acceder a la webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"✅ Webcam iniciada\")\n",
    "    print(\"\\n📋 CONTROLES:\")\n",
    "    print(\"  - Presiona 'q' para salir\")\n",
    "    print(\"  - Presiona 's' para guardar screenshot\")\n",
    "    print(\"  - Presiona ESC para salir\")\n",
    "    print(\"\\n🎭 ¡Haz diferentes expresiones faciales!\")\n",
    "    \n",
    "    screenshot_count = 0\n",
    "    \n",
    "    while True:\n",
    "        # Capturar frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"❌ Error al capturar frame\")\n",
    "            break\n",
    "        \n",
    "        # Convertir a escala de grises para detección\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detectar rostros\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(48, 48)\n",
    "        )\n",
    "        \n",
    "        # Procesar cada rostro detectado\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extraer región del rostro\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            # Predecir emoción\n",
    "            emotion, confidence, all_predictions = predict_emotion(face_roi, model)\n",
    "            \n",
    "            # Dibujar resultados\n",
    "            frame = draw_emotion_results(frame, x, y, w, h, emotion, confidence)\n",
    "        \n",
    "        # Mostrar información en pantalla\n",
    "        cv2.putText(frame, f\"Rostros detectados: {len(faces)}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, \"Presiona 'q' para salir | 's' para screenshot\", (10, frame.shape[0] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Mostrar frame\n",
    "        cv2.imshow('Detector de Emociones Faciales', frame)\n",
    "        \n",
    "        # Controles de teclado\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == 27:  # 'q' o ESC\n",
    "            print(\"\\n👋 Cerrando aplicación...\")\n",
    "            break\n",
    "        elif key == ord('s'):  # Guardar screenshot\n",
    "            screenshot_count += 1\n",
    "            filename = f'../data/screenshot_{screenshot_count}.jpg'\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"📸 Screenshot guardado: {filename}\")\n",
    "    \n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"✅ Aplicación cerrada correctamente\")\n",
    "\n",
    "\n",
    "print(\"✅ Función de detección en tiempo real creada\")\n",
    "print(\"\\n🚀 Para iniciar la detección, ejecuta la siguiente celda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caba088",
   "metadata": {},
   "source": [
    "## 🚀 ¡Iniciar Detección!\n",
    "\n",
    "Ejecuta la siguiente celda para activar tu webcam y empezar a detectar emociones.\n",
    "\n",
    "**Tips:**\n",
    "- Asegúrate de tener buena iluminación\n",
    "- Mira directamente a la cámara\n",
    "- Prueba diferentes expresiones: sonríe, enójate, sorpréndete\n",
    "- El modelo funciona mejor con expresiones claras y exageradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd184f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🎥 DETECTOR DE EMOCIONES FACIALES EN TIEMPO REAL\n",
      "============================================================\n",
      "🎥 Iniciando webcam...\n",
      "✅ Webcam iniciada\n",
      "\n",
      "📋 CONTROLES:\n",
      "  - Presiona 'q' para salir\n",
      "  - Presiona 's' para guardar screenshot\n",
      "  - Presiona ESC para salir\n",
      "\n",
      "🎭 ¡Haz diferentes expresiones faciales!\n"
     ]
    }
   ],
   "source": [
    "# ¡INICIAR DETECCIÓN DE EMOCIONES!\n",
    "print(\"=\" * 60)\n",
    "print(\"🎥 DETECTOR DE EMOCIONES FACIALES EN TIEMPO REAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "run_emotion_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detector-emociones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
